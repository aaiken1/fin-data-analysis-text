{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data importing\n",
    "\n",
    "Let's start by getting some data into Python. This will usually be the first step in our code, right after we import any of the libraries, like `numpy` and `pandas` that we need.\n",
    "\n",
    "There is a [DataCamp tutorial on Excel files and Python](https://www.datacamp.com/community/tutorials/python-excel-tutorial) that you might find helpful. You can read also more about [reading in CSV files at DataCamp](https://www.datacamp.com/community/tutorials/pandas-read-csv). \n",
    "\n",
    "There's some price data up on our [course Github page](https://github.com/aaiken1/fin-data-analysis-python). Let's import this both as a downloaded CSV file and directly from Github, with no download. \n",
    "\n",
    "First, we need to import `pandas`. Just like `numpy`. In fact, at the top of basically all of your code, you will import both of these libraries (and more!).\n",
    "\n",
    "Everyone imports `pandas` as pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by making a DataFrame ourself, just to see how they are different from `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([75,79,82,60], columns = ['Prices'], index =[1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to the example on pgs. 114 - 115 of our textbook. I am creating a DataFrame with one column. This column has four stock prices. I am labeling that column as `Prices`. I then have an `index` value that refers to each row. I am using numbers. This could easily be a date!\n",
    "\n",
    "See how this is kind of like a spreadsheet? And, unlike an array, we have **labels** or **headers** for columns. And we have indexes for each row that aren't really part of the data. \n",
    "\n",
    "We'll do more with this in the next section.\n",
    "\n",
    "Ok, let's import that CSV file into a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv('../data/tr_eikon_eod_data.csv',\n",
    "                  index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, click the **Variables** button at the top. You'll see the two DataFrames that we now have in memory appear below. Click the pop-out button to view them.\n",
    "\n",
    "Notice how I did the path name. `../` means to start start from my home directory. What's my home directory? That's where you `.ipynb` file lives. **Relative** to that directory, Python looks for a folder called `data`. Finally, it looks for the .csv file called `tr_eikon_eod_data.csv` inside of that folder.\n",
    "\n",
    "What are those other options doing? `index_col=0` tells `pandas` to create a DataFrame where column 0 (the first column in the .csv file) is the index. Check out the CSV file - that's the date. With finance data, the date will often be the index, since we are dealing with time series data (e.g. stock prices or returns).\n",
    "\n",
    "The option `parse_dates` is telling `pandas` to look at the index column and try to turn what it sees into official Python dates. That works in this case. Finance coders will joke that 90% of their time is spend doing date corrections. For example, what happens if you have multiple markets in different time zones and you're trying to deal with time series at a trade-level frequency (i.e. less than a second)? Have fun!\n",
    "\n",
    "You can read about the `pd.read_csv` method on the [`pandas` web page](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html).\n",
    "\n",
    "You can also write Python data to a .csv or Excel file. Our DataCamp assignments will go over all of this.\n",
    "\n",
    "Let's now read in this file directly from our class Github. I'll call the resulting DataFrame `prices2`, just so that we can see that we actually have the same thing twice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices2 = pd.read_csv('https://github.com/aaiken1/fin-data-analysis-python/raw/main/data/tr_eikon_eod_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made a \"mistake\" on purpose there. Notice how I didn't do the `index_col`? Check out the `prices2` DataFrame below. You'll see an index column with 1, 2, 3,.. and then the date column. The `read_csv` created an index for me, since I didn't specify one. Let's redo that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices2 = pd.read_csv('https://github.com/aaiken1/fin-data-analysis-python/raw/main/data/tr_eikon_eod_data.csv',\n",
    "                      index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better! We'll end by looking at some of the **attributes** of our `prices` DataFrame.\n",
    "\n",
    "First, let's check our index. Is it really a date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2010-01-01', '2010-01-04', '2010-01-05', '2010-01-06',\n",
       "               '2010-01-07', '2010-01-08', '2010-01-11', '2010-01-12',\n",
       "               '2010-01-13', '2010-01-14',\n",
       "               ...\n",
       "               '2018-06-18', '2018-06-19', '2018-06-20', '2018-06-21',\n",
       "               '2018-06-22', '2018-06-25', '2018-06-26', '2018-06-27',\n",
       "               '2018-06-28', '2018-06-29'],\n",
       "              dtype='datetime64[ns]', name='Date', length=2216, freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is! We'll do more with dates. A lot more. \n",
    "\n",
    "Let's look at the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AAPL.O', 'MSFT.O', 'INTC.O', 'AMZN.O', 'GS.N', 'SPY', '.SPX', '.VIX',\n",
       "       'EUR=', 'XAU=', 'GDX', 'GLD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, those are our column headers from the .csv file.\n",
    "\n",
    "We have our data in Python! Now, we can manipulate it, clean it, merge it with something else, summarize it, plot it, and do some actual finance."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b67b392f8c699abfccff34ffff3abf55b26d6520ea7ac337064f990a3d8607af"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
